{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 05:15:42.884291: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-13 05:15:43.525192: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# import from the auxFunctions.py file\n",
    "from auxFunctions import calculate_mae_and_mrrmse, mean_rowwise_rmse_loss, custom_mean_rowwise_rmse, create_model_checkpoint, plot_training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre-process data\n",
    "one-hot encode cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_train = pl.scan_parquet('./de_train.parquet')\n",
    "de_train_df = de_train.collect().to_pandas()\n",
    "\n",
    "# test provided by kaggle --> upload predictions to kaggle to get the score\n",
    "id_map = pd.read_csv('./id_map.csv')\n",
    "\n",
    "affinities = pd.read_csv('affinities_Transformer_CNN_BindingDB.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train dataset provided by kaggle\n",
    "- will be split into train/test/validation for internal testing before model is trained on the entire train and used to predict on the test in id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAffinities(sm_names, affinities):\n",
    "    \"\"\"\n",
    "    Function to extract affinities from the affinities dataframe\n",
    "\n",
    "    Parameters:\n",
    "    - sm_names: List/Array of sm_names\n",
    "    - affinities: Stored affinities predicted using DeepPurpose\n",
    "\n",
    "    Returns:\n",
    "    - Affinities as a numpy array\n",
    "    \"\"\"\n",
    "    encoded_affinities = []\n",
    "    for name in sm_names:\n",
    "        filtered = affinities[affinities['sm_name'] == name]\n",
    "        sm_affinities = filtered.iloc[:, 2:].values[0]\n",
    "        encoded_affinities.append(sm_affinities)\n",
    "\n",
    "    np_encoded_affinities = np.array(encoded_affinities)\n",
    "\n",
    "    return np_encoded_affinities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1.0\n",
      "  (1, 3)\t1.0\n",
      "  (2, 4)\t1.0\n",
      "  (3, 5)\t1.0\n",
      "  (4, 2)\t1.0\n",
      "  (5, 3)\t1.0\n",
      "  (6, 4)\t1.0\n",
      "  (7, 5)\t1.0\n",
      "  (8, 0)\t1.0\n",
      "  (9, 1)\t1.0\n",
      "  (10, 2)\t1.0\n",
      "  (11, 3)\t1.0\n",
      "  (12, 4)\t1.0\n",
      "  (13, 5)\t1.0\n",
      "  (14, 2)\t1.0\n",
      "  (15, 3)\t1.0\n",
      "  (16, 4)\t1.0\n",
      "  (17, 5)\t1.0\n",
      "  (18, 2)\t1.0\n",
      "  (19, 3)\t1.0\n",
      "  (20, 4)\t1.0\n",
      "  (21, 5)\t1.0\n",
      "  (22, 2)\t1.0\n",
      "  (23, 3)\t1.0\n",
      "  (24, 4)\t1.0\n",
      "  :\t:\n",
      "  (589, 5)\t1.0\n",
      "  (590, 2)\t1.0\n",
      "  (591, 3)\t1.0\n",
      "  (592, 4)\t1.0\n",
      "  (593, 5)\t1.0\n",
      "  (594, 2)\t1.0\n",
      "  (595, 3)\t1.0\n",
      "  (596, 4)\t1.0\n",
      "  (597, 5)\t1.0\n",
      "  (598, 2)\t1.0\n",
      "  (599, 3)\t1.0\n",
      "  (600, 4)\t1.0\n",
      "  (601, 5)\t1.0\n",
      "  (602, 2)\t1.0\n",
      "  (603, 3)\t1.0\n",
      "  (604, 4)\t1.0\n",
      "  (605, 5)\t1.0\n",
      "  (606, 2)\t1.0\n",
      "  (607, 3)\t1.0\n",
      "  (608, 4)\t1.0\n",
      "  (609, 5)\t1.0\n",
      "  (610, 2)\t1.0\n",
      "  (611, 3)\t1.0\n",
      "  (612, 4)\t1.0\n",
      "  (613, 5)\t1.0\n"
     ]
    }
   ],
   "source": [
    "# one-hot encode cell_type\n",
    "cell_type = de_train_df['cell_type'].to_numpy().reshape(-1, 1)\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(cell_type)\n",
    "\n",
    "# of type scipy.sparse._csr.csr_matrix\n",
    "encoded_cell_type = encoder.transform(cell_type)\n",
    "\n",
    "# map sm_name to affinities\n",
    "sm_name = de_train_df['sm_name']\n",
    "\n",
    "# has shape (614, 12766), of type numpy.ndarray\n",
    "#this is the training set\n",
    "np_encoded_affinities = extractAffinities(sm_name, affinities)\n",
    "\n",
    "# concatenate encoded_cell_type and np_encoded_affinities\n",
    "# final shape (614, 12772)\n",
    "encoded_features = np.hstack((encoded_cell_type.toarray(), np_encoded_affinities))\n",
    "\n",
    "print(encoded_cell_type)\n",
    "\n",
    "\n",
    "# wanted output\n",
    "genes_lfc = de_train_df.drop(columns=['cell_type', 'sm_name', 'sm_lincs_id', 'SMILES', 'control'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for kaggle test set\n",
    "kaggle_cell_type = id_map['cell_type'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "\n",
    "encoded_kaggle_cell_type = encoder.transform(kaggle_cell_type)\n",
    "\n",
    "\n",
    "\n",
    "kaggle_sm_name = id_map['sm_name']\n",
    "\n",
    "#This is for the test data set\n",
    "encoded_kaggle_affinities = extractAffinities(kaggle_sm_name, affinities)\n",
    "\n",
    "\n",
    "# final shape (255, 12772)\n",
    "encoded_kaggle_features = np.hstack((encoded_kaggle_cell_type.toarray(), encoded_kaggle_affinities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10472047 -0.07752421 -1.62559604 ...  0.03412678  0.22137655\n",
      "   0.36875538]\n",
      " [ 0.91595324 -0.88438038  0.37183448 ...  0.70477983  1.09670189\n",
      "  -0.86988664]\n",
      " [-0.38772076 -0.30537826  0.56777737 ...  0.41576793  0.07843919\n",
      "  -0.25936541]\n",
      " ...\n",
      " [ 0.61950832 -0.03779631  0.87478376 ... -0.95027954 -0.49932213\n",
      "   0.11094977]\n",
      " [-0.1314054   0.17761662 -0.11689098 ...  0.25845771 -0.29531843\n",
      "  -0.3699244 ]\n",
      " [ 1.07188372 -0.35765163  0.17995645 ... -0.48290495 -0.4353545\n",
      "  -0.23529439]]\n"
     ]
    }
   ],
   "source": [
    "# Split the data into 70% training, 15% validation, and 15% testing\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(encoded_features, genes_lfc.values, test_size=0.3, shuffle=False)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, shuffle=False)\n",
    "\n",
    "# used for final training before predicting on kaggle_test\n",
    "full_features = encoded_features\n",
    "full_labels = genes_lfc.values\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Activation, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##define search space\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 5)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                # Tune number of units separately.\n",
    "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=18211, step=32),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    model.add(layers.Dense(18211, activation=\"linear\"))\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=mean_rowwise_rmse_loss, metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 05:16:03.514551: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x7f135693ceb0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_model(keras_tuner.HyperParameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select tuner classs to run search\n",
    "\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=keras_tuner.Objective(\"val_root_mean_squared_error\", direction=\"min\"),\n",
    "    max_trials=10,\n",
    "    executions_per_trial=3,\n",
    "    overwrite=True,\n",
    "    directory=\"models\",\n",
    "    project_name=\"model_3\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 3\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 5, 'step': 1, 'sampling': 'linear'}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 18211, 'step': 32, 'sampling': 'linear'}\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "#search space summary\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 7 Complete [00h 00m 36s]\n",
      "val_root_mean_squared_error: 1.0060972770055134\n",
      "\n",
      "Best val_root_mean_squared_error So Far: 0.9800203045209249\n",
      "Total elapsed time: 00h 10m 17s\n",
      "\n",
      "Search: Running Trial #8\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "4                 |5                 |num_layers\n",
      "10720             |2400              |units_0\n",
      "relu              |tanh              |activation\n",
      "17472             |32                |units_1\n",
      "1920              |32                |units_2\n",
      "15520             |32                |units_3\n",
      "5856              |32                |units_4\n",
      "\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 61s 4s/step - loss: 12.7084 - root_mean_squared_error: 33.0734 - val_loss: 0.8456 - val_root_mean_squared_error: 1.0070\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 66s 5s/step - loss: 1.3668 - root_mean_squared_error: 2.6369 - val_loss: 0.8372 - val_root_mean_squared_error: 0.9971\n",
      "Epoch 1/2\n",
      "14/14 [==============================] - 30s 2s/step - loss: 12.1871 - root_mean_squared_error: 31.8530 - val_loss: 1.1980 - val_root_mean_squared_error: 1.2838\n",
      "Epoch 2/2\n",
      "14/14 [==============================] - 71s 5s/step - loss: 1.4055 - root_mean_squared_error: 2.6378 - val_loss: 0.8365 - val_root_mean_squared_error: 0.9954\n",
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train, y_train, epochs=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner.get_best_models(num_models=2)\n",
    "best_model = models[0]\n",
    "# Build the model.\n",
    "# Needed for `Sequential` without specified `input_shape`.\n",
    "best_model.build(input_shape=(614, 12772))\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hps = tuner.get_best_hyperparameters(5)\n",
    "# Build the model with the best hp.\n",
    "model_tuned = build_model(best_hps[0])\n",
    "# Fit with the entire dataset.\n",
    "x_all = np.concatenate((x_train, y_val))\n",
    "y_all = np.concatenate((y_train, y_val))\n",
    "model_tuned.fit(x=x_all, y=y_all, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.saved(\"model_3\")\n",
    "model.save_weights(\"model_3_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_mae_and_mrrmse(model=model_tuned, data=X_test, y_true=y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
