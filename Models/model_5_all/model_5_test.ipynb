{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-14 00:11:27.839361: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-14 00:11:28.201270: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-14 00:11:28.201315: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-14 00:11:28.203415: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-14 00:11:28.359341: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "# import from the auxFunctions.py file\n",
    "from auxFunctions import calculate_mae_and_mrrmse, mean_rowwise_rmse_loss, custom_mean_rowwise_rmse, create_model_checkpoint, plot_training_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_train = pl.scan_parquet('de_train.parquet')\n",
    "de_train_df = de_train.collect().to_pandas()\n",
    "\n",
    "# test provided by kaggle --> upload predictions to kaggle to get the score\n",
    "id_map = pd.read_csv('id_map.csv')\n",
    "\n",
    "affinities = pd.read_csv('affinities_Transformer_CNN_BindingDB.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('model_5',custom_objects={\"mean_rowwise_rmse_loss\": \"root_mean_squared_error\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 3400)              43428200  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3000)              10203000  \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 2100)              6302100   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 200)               420200    \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 200)               40200     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 18211)             3660411   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64054111 (244.35 MB)\n",
      "Trainable params: 64054111 (244.35 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 3400, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 3000, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 2100, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'dense_7', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'dense_8', 'trainable': True, 'dtype': 'float32', 'units': 200, 'activation': 'tanh', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "{'name': 'dropout', 'trainable': True, 'dtype': 'float32', 'rate': 0.25, 'noise_shape': None, 'seed': None}\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print(model.layers[i].get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractAffinities(sm_names, affinities):\n",
    "    \"\"\"\n",
    "    Function to extract affinities from the affinities dataframe\n",
    "\n",
    "    Parameters:\n",
    "    - sm_names: List/Array of sm_names\n",
    "    - affinities: Stored affinities predicted using DeepPurpose\n",
    "\n",
    "    Returns:\n",
    "    - Affinities as a numpy array\n",
    "    \"\"\"\n",
    "    encoded_affinities = []\n",
    "    for name in sm_names:\n",
    "        filtered = affinities[affinities['sm_name'] == name]\n",
    "        sm_affinities = filtered.iloc[:, 2:].values[0]\n",
    "        encoded_affinities.append(sm_affinities)\n",
    "\n",
    "    np_encoded_affinities = np.array(encoded_affinities)\n",
    "\n",
    "    return np_encoded_affinities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode cell_type\n",
    "cell_type = de_train_df['cell_type'].to_numpy().reshape(-1, 1)\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(cell_type)\n",
    "# of type scipy.sparse._csr.csr_matrix\n",
    "encoded_cell_type = encoder.transform(cell_type)\n",
    "\n",
    "# map sm_name to affinities\n",
    "sm_name = de_train_df['sm_name']\n",
    "\n",
    "# has shape (614, 12766), of type numpy.ndarray\n",
    "np_encoded_affinities = extractAffinities(sm_name, affinities)\n",
    "\n",
    "# concatenate encoded_cell_type and np_encoded_affinities\n",
    "# final shape (614, 12772)\n",
    "encoded_features = np.hstack((encoded_cell_type.toarray(), np_encoded_affinities))\n",
    "\n",
    "# wanted output\n",
    "genes_lfc = de_train_df.drop(columns=['cell_type', 'sm_name', 'sm_lincs_id', 'SMILES', 'control'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for kaggle test set\n",
    "kaggle_cell_type = id_map['cell_type'].to_numpy().reshape(-1, 1)\n",
    "encoded_kaggle_cell_type = encoder.transform(kaggle_cell_type)\n",
    "\n",
    "kaggle_sm_name = id_map['sm_name']\n",
    "encoded_kaggle_affinities = extractAffinities(kaggle_sm_name, affinities)\n",
    "\n",
    "# final shape (255, 12772)\n",
    "encoded_kaggle_features = np.hstack((encoded_kaggle_cell_type.toarray(), encoded_kaggle_affinities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255/255 [==============================] - 5s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "kaggle_predictions = model.predict(encoded_kaggle_features, batch_size=1)\n",
    "\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "sample_submission.iloc[:,1:] = kaggle_predictions\n",
    "\n",
    "sample_submission.to_csv('submission_model_4.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
